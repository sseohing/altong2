{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b3081",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-cloud-storage\n",
    "%pip install google-cloud-speech\n",
    "%pip install --upgrade google-cloud-texttospeech\n",
    "%pip install pyttsx3\n",
    "%pip install playsound\n",
    "%pip install pygame\n",
    "%pip install openai langchain\n",
    "%pip install gtts pygame\n",
    "%pip install playsound==1.2.2\n",
    "%pip install pinecone-client\n",
    "%pip install openai==1.2.0\n",
    "%pip install pyaudio\n",
    "%pip install simpleaudio\n",
    "%pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ec21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2.0 인지 확인\n",
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e720622",
   "metadata": {},
   "source": [
    "## content에 쓴 내용 stream 형식으로 출력 (채팅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43dafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key ='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba4238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"너무 피곤하다\"}],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f9919f",
   "metadata": {},
   "source": [
    "## stream 형식으로 tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b079f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pyttsx3\n",
    "import gTTS\n",
    "\n",
    "def text_to_speech(text, lang='ko', filename='outSound.mp3'):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "    print(\"speaking start\")\n",
    "    playsound(filename)\n",
    "    print(\"speaking end\")\n",
    "    os.remove(filename)\n",
    "    \n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "engine = pyttsx3.init()\n",
    "out = \"\"\n",
    "for chunk in openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"인공지능에 대한 소설을 써줘\" # content 부분에 요청\n",
    "    }],\n",
    "    stream=True,\n",
    "):\n",
    "    content = chunk[\"choices\"][0].get(\"delta\", {}).get(\"content\")\n",
    "    if content is not None:\n",
    "        out += content\n",
    "    \n",
    "    if len(out) >= 50 and out[-1] == '.':\n",
    "        text_to_speech(out)\n",
    "        out = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c08cbb",
   "metadata": {},
   "source": [
    "## pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"e51a52b1-749d-4f5f-9ac8-480f2dd68623\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b831481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinecone index 확인\n",
    "import pinecone\n",
    "api_key = api_key\n",
    "pinecone.init(api_key=api_key, environment='gcp-starter')\n",
    "\n",
    "index_name = \"popo\"\n",
    "index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f96877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai api로 embbeding하는 함수 !!\n",
    "from openai import OpenAI\n",
    "\n",
    "# from openai import OpenAI\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "client = OpenAI()\n",
    "# print(oa.version)\n",
    "# client = oa.OpenAI()\n",
    "\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=\"시작\",\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "\n",
    "\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 pinecone index에 upsert 하기\n",
    "from openai import OpenAI\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "client = OpenAI()\n",
    "\n",
    "text = \"몇 시간 했지\"\n",
    "\n",
    "response = client.embeddings.create(\n",
    "        input= text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "\n",
    "index.upsert([\n",
    "    (\"record\", response.data[0].embedding)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5cff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문쿼리 !!\n",
    "\n",
    "import openai\n",
    "import os\n",
    "import pinecone\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "api_key = api_key\n",
    "pinecone.init(api_key=api_key, environment='gcp-starter')\n",
    "index_name = \"popo\"\n",
    "index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    print(text)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def embeding_query(text):\n",
    "    query_result = index.query(\n",
    "        get_embedding(text), \n",
    "        top_k=1,      \n",
    "        include_values=False  \n",
    "    )\n",
    "    print(query_result)\n",
    "    \n",
    "    \n",
    "embeding_query(\"몇시간했지\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc3d2c",
   "metadata": {},
   "source": [
    "## score 어느정도 이상이면 대답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pinecone\n",
    "import os\n",
    "import io\n",
    "import wave\n",
    "import pyaudio\n",
    "import time\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from gtts import gTTS\n",
    "import subprocess\n",
    "from playsound import playsound\n",
    "\n",
    "# pinecone\n",
    "pinecone.init(api_key=api_key, environment='gcp-starter')\n",
    "index_name = \"popo\"\n",
    "index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "# Google Cloud 프로젝트 및 서비스 계정 키\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/SMHRD/Downloads/popoteststt-31bc6d0f3189.json\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "api_key = api_key\n",
    "pinecone.init(api_key=api_key, environment='gcp-starter')\n",
    "client = OpenAI()\n",
    "\n",
    "# text를 임베딩하는 함수\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "#     if response.status.code == 200:\n",
    "    print(\"Text:\", text)\n",
    "    return response.data[0].embedding\n",
    "#     else:\n",
    "#         print(\"Error in embedding:\", response.errors)\n",
    "#         return None\n",
    "\n",
    "\n",
    "# 질문 쿼리\n",
    "def embeding_query(text):\n",
    "    query_result = index.query(\n",
    "        get_embedding(text), \n",
    "        top_k=1,      \n",
    "        include_values=False  \n",
    "    )\n",
    "    print(\"Query Result:\", query_result)\n",
    "    return query_result\n",
    "\n",
    "\n",
    "def is_user_talking(file_path):\n",
    "    # 음성 신호 세기가 일정 값 이상이면 사용자가 말하고 있다고 판단\n",
    "    silence_threshold = 500  # 예시로 설정한 음성 신호 강도 임계값\n",
    "\n",
    "    return get_audio_signal_strength(file_path) > silence_threshold\n",
    "\n",
    "\n",
    "# gTTS 라이브러리를 사용하여 텍스트를 지정된 언어로 음성으로 변환하고 MP3 파일로 저장, 재생        \n",
    "def text_to_speech(text, lang='ko', filename='outSound.mp3'):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "    print(\"speaking start\")\n",
    "    playsound(filename)\n",
    "    print(\"speaking end\")\n",
    "    os.remove(filename)\n",
    "    \n",
    "\n",
    "# stt API를 사용하여 음성 파일에서 텍스트를 추출\n",
    "def transcribe_audio(audio_file_path):\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(audio_file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,  \n",
    "        language_code=\"ko-KR\",\n",
    "    )\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    # 첫 번째 결과만 사용\n",
    "    signal_strength = get_audio_signal_strength(audio_file_path)\n",
    "    if response.results:\n",
    "        transcribed_text = response.results[0].alternatives[0].transcript\n",
    "        return transcribed_text, signal_strength\n",
    "    else:\n",
    "        return \"No speech detected\", signal_strength\n",
    "    \n",
    "\n",
    "# PyAudio를 사용하여 지정된 시간 동안 음성을 녹음하고 WAV 파일로 저장\n",
    "def record_audio(file_path, duration=10):\n",
    "    chunk = 1024\n",
    "    sample_format = pyaudio.paInt16\n",
    "    channels = 1\n",
    "    fs = 16000\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(\n",
    "        format=sample_format,\n",
    "        channels=channels,\n",
    "        rate=fs,\n",
    "        frames_per_buffer=chunk,\n",
    "        input=True,\n",
    "    )\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    for i in range(0, int(fs / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished listening.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    with wave.open(file_path, \"wb\") as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(pyaudio.PyAudio().get_sample_size(sample_format))\n",
    "        wf.setframerate(fs)\n",
    "        wf.writeframes(b\"\".join(frames))\n",
    "\n",
    "        \n",
    "def get_audio_signal_strength(file_path):\n",
    "    from scipy.io import wavfile\n",
    "    samplerate, data = wavfile.read(file_path)\n",
    "    isLoud = False\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         plt.plot([frame for frame in data])\n",
    "#         plt.show()\n",
    "\n",
    "    return max(data)\n",
    "    \n",
    "\n",
    "def transcribe_and_speak(file_path, keyword, duration=5):\n",
    "    start_time = time.time()  # 시작 시간 저장\n",
    "    silence_threshold = 500  # 음성 신호 강도 임계값\n",
    "    silence_duration = 5  # 음성 신호 없음으로 판단하는 지속 시간 (초)\n",
    "\n",
    "    # 무한 루프로 계속해서 음성 감지\n",
    "    while True:\n",
    "        # 음성 녹음\n",
    "        record_audio(file_path, duration)\n",
    "\n",
    "        # 음성을 텍스트로 변환\n",
    "        transcribed_text = transcribe_audio(file_path)\n",
    "\n",
    "        # 변환된 텍스트를 출력\n",
    "        print(\"Transcribed Text:\", transcribed_text)\n",
    "        \n",
    "        # embeding_query 함수를 호출하여 query_result를 얻어오기\n",
    "        query_result = embeding_query(transcribed_text[0])\n",
    "\n",
    "        ###\n",
    "        if keyword in transcribed_text:\n",
    "            text_to_speech(\"네, 알통이 등장! 부르셨어요?\", lang='ko', filename='outSound.mp3')\n",
    "            \n",
    "        # 특정 시간 동안 아무 음성도 감지되지 않으면 종료\n",
    "        elif not is_user_talking(file_path):\n",
    "            text_to_speech(\"아무 말도 없으셔서 종료합니다.\", lang='ko', filename='outSound.mp3')\n",
    "            break\n",
    "            \n",
    "        elif query_result['matches'][0]['id'] == 'start' and query_result['matches'][0]['score'] >= 0.85:\n",
    "            text_to_speech(\"넵, 운동을 시작합니다!\", lang='ko', filename='outSound.mp3')\n",
    "            \n",
    "        elif query_result['matches'][0]['id'] == 'end' and query_result['matches'][0]['score'] >= 0.85:\n",
    "            text_to_speech(\"넵, 운동을 종료합니다!\", lang='ko', filename='outSound.mp3')\n",
    "            \n",
    "        elif query_result['matches'][0]['id'] == 'next' and query_result['matches'][0]['score'] >= 0.85:\n",
    "            text_to_speech(\"다음 운동은 스쿼트 입니다!\", lang='ko', filename='outSound.mp3')\n",
    "            \n",
    "        elif query_result['matches'][0]['id'] == 'record' and query_result['matches'][0]['score'] >= 0.85:\n",
    "            text_to_speech(\"오늘 운동한 시간은 총 30분 입니다!\", lang='ko', filename='outSound.mp3')\n",
    "            \n",
    "        elif query_result['matches'][0]['id'] == 'calorie' and query_result['matches'][0]['score'] >= 0.85:\n",
    "            text_to_speech(\"오늘 소비한 칼로리는 총 100칼로리 입니다!\", lang='ko', filename='outSound.mp3')          \n",
    "        \n",
    "        # 정확도 (score)가 0.85 이하일 경우    \n",
    "        elif is_user_talking(file_path) and query_result['matches'][0]['score'] < 0.85:\n",
    "            text_to_speech(\"다시 말해주세요 !\", lang='ko', filename='outSound.mp3')\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    audio_file_path = \"outSound.wav\"\n",
    "\n",
    "    transcribe_and_speak(audio_file_path, keyword=\"알통\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d553bd4",
   "metadata": {},
   "source": [
    "## 무한으로 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pinecone\n",
    "import os\n",
    "import io\n",
    "import wave\n",
    "import pyaudio\n",
    "import time\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from gtts import gTTS\n",
    "import subprocess\n",
    "from playsound import playsound\n",
    "\n",
    "# pinecone\n",
    "pinecone.init(api_key=api_key, environment='gcp-starter')\n",
    "index_name = \"popo\"\n",
    "index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "# Google Cloud 프로젝트 및 서비스 계정 키\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/SMHRD/Downloads/popoteststt-31bc6d0f3189.json\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "api_key = api_key\n",
    "pinecone.init(api_key=api_key, environment='gcp-starter')\n",
    "client = OpenAI()\n",
    "\n",
    "# text를 임베딩하는 함수\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "#     if response.status.code == 200:\n",
    "    print(\"Text:\", text)\n",
    "    return response.data[0].embedding\n",
    "#     else:\n",
    "#         print(\"Error in embedding:\", response.errors)\n",
    "#         return None\n",
    "\n",
    "\n",
    "# 질문 쿼리\n",
    "def embeding_query(text):\n",
    "    query_result = index.query(\n",
    "        get_embedding(text), \n",
    "        top_k=1,      \n",
    "        include_values=False  \n",
    "    )\n",
    "    print(\"Query Result:\", query_result)\n",
    "    return query_result\n",
    "\n",
    "\n",
    "def is_user_talking(file_path):\n",
    "    # 음성 신호 세기가 일정 값 이상이면 사용자가 말하고 있다고 판단\n",
    "    silence_threshold = 2500  # 예시로 설정한 음성 신호 강도 임계값\n",
    "\n",
    "    return get_audio_signal_strength(file_path) > silence_threshold\n",
    "\n",
    "\n",
    "# gTTS 라이브러리를 사용하여 텍스트를 지정된 언어로 음성으로 변환하고 MP3 파일로 저장, 재생        \n",
    "def text_to_speech(text, lang='ko', filename='outSound.mp3'):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "    print(\"speaking start\")\n",
    "    playsound(filename)\n",
    "    print(\"speaking end\")\n",
    "    os.remove(filename)\n",
    "    \n",
    "\n",
    "# stt API를 사용하여 음성 파일에서 텍스트를 추출\n",
    "def transcribe_audio(audio_file_path):\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(audio_file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,  \n",
    "        language_code=\"ko-KR\",\n",
    "    )\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    # 첫 번째 결과만 사용\n",
    "    signal_strength = get_audio_signal_strength(audio_file_path)\n",
    "    if response.results:\n",
    "        transcribed_text = response.results[0].alternatives[0].transcript\n",
    "        return transcribed_text, signal_strength\n",
    "    else:\n",
    "        return \"No speech detected\", signal_strength\n",
    "    \n",
    "\n",
    "# PyAudio를 사용하여 지정된 시간 동안 음성을 녹음하고 WAV 파일로 저장\n",
    "def record_audio(file_path, duration=10):\n",
    "    chunk = 1024\n",
    "    sample_format = pyaudio.paInt16\n",
    "    channels = 1\n",
    "    fs = 16000\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(\n",
    "        format=sample_format,\n",
    "        channels=channels,\n",
    "        rate=fs,\n",
    "        frames_per_buffer=chunk,\n",
    "        input=True,\n",
    "    )\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    for i in range(0, int(fs / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished listening.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    with wave.open(file_path, \"wb\") as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(pyaudio.PyAudio().get_sample_size(sample_format))\n",
    "        wf.setframerate(fs)\n",
    "        wf.writeframes(b\"\".join(frames))\n",
    "\n",
    "        \n",
    "def get_audio_signal_strength(file_path):\n",
    "    from scipy.io import wavfile\n",
    "    samplerate, data = wavfile.read(file_path)\n",
    "    isLoud = False\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         plt.plot([frame for frame in data])\n",
    "#         plt.show()\n",
    "\n",
    "    return max(data)\n",
    "    \n",
    "\n",
    "def transcribe_and_speak(file_path, keyword, duration=5):\n",
    "    start_time = time.time()  # 시작 시간 저장\n",
    "    silence_threshold = 500  # 음성 신호 강도 임계값\n",
    "    silence_duration = 5  # 음성 신호 없음으로 판단하는 지속 시간 (초)\n",
    "\n",
    "    # 무한 루프로 계속해서 음성 감지\n",
    "    while True:\n",
    "        # 음성 녹음\n",
    "        record_audio(file_path, duration)\n",
    "\n",
    "        # 음성을 텍스트로 변환\n",
    "        transcribed_text = transcribe_audio(file_path)\n",
    "\n",
    "        # 변환된 텍스트를 출력\n",
    "        print(\"Transcribed Text:\", transcribed_text)\n",
    "        \n",
    "        # embeding_query 함수를 호출하여 query_result를 얻어오기\n",
    "        query_result = embeding_query(transcribed_text[0])\n",
    "\n",
    "        ###\n",
    "        if keyword in transcribed_text:\n",
    "            text_to_speech(\"네, 알통이 등장! 부르셨어요?\", lang='ko', filename='outSound.mp3')\n",
    "            \n",
    "            while True:\n",
    "                # 특정 시간 동안 아무 음성도 감지되지 않으면 종료\n",
    "                if not is_user_talking(file_path):\n",
    "                    text_to_speech(\"아무 말도 없으셔서 종료합니다.\", lang='ko', filename='outSound.mp3')\n",
    "                    break\n",
    "\n",
    "                elif query_result['matches'][0]['id'] == 'start' and query_result['matches'][0]['score'] >= 0.85:\n",
    "                    text_to_speech(\"넵, 운동을 시작합니다!\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "                elif query_result['matches'][0]['id'] == 'end' and query_result['matches'][0]['score'] >= 0.85:\n",
    "                    text_to_speech(\"넵, 운동을 종료합니다!\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "                elif query_result['matches'][0]['id'] == 'next' and query_result['matches'][0]['score'] >= 0.85:\n",
    "                    text_to_speech(\"다음 운동은 스쿼트 입니다!\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "                elif query_result['matches'][0]['id'] == 'record' and query_result['matches'][0]['score'] >= 0.85:\n",
    "                    text_to_speech(\"오늘 운동한 시간은 총 30분 입니다!\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "                elif query_result['matches'][0]['id'] == 'calorie' and query_result['matches'][0]['score'] >= 0.85:\n",
    "                    text_to_speech(\"오늘 소비한 칼로리는 총 100칼로리 입니다!\", lang='ko', filename='outSound.mp3')          \n",
    "\n",
    "                # 정확도 (score)가 0.85 이하일 경우    \n",
    "                elif is_user_talking(file_path) and query_result['matches'][0]['score'] < 0.85:\n",
    "                    text_to_speech(\"다시 말해주세요 !\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file_path = \"outSound.wav\"\n",
    "\n",
    "    transcribe_and_speak(audio_file_path, keyword=\"알통\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1982bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff2e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfe09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
